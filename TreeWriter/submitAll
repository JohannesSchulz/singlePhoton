#!/bin/bash
# This script submitts all jobs to naf, which are defined in dataset

datasets=(
# srm://dcache-se-cms.desy.de:8443/srm/managerv2?SFN=/pnfs/desy.de/cms/tier2/store/user/jschulz/nTuples/QCD_250-500_V01/
# srm://dcache-se-cms.desy.de:8443/srm/managerv2?SFN=/pnfs/desy.de/cms/tier2/store/user/jschulz/nTuples/QCD_500-1000_V01/
# srm://dcache-se-cms.desy.de:8443/srm/managerv2?SFN=/pnfs/desy.de/cms/tier2/store/user/jschulz/nTuples/QCD_1000-inf_V01/
 srm://dcache-se-cms.desy.de:8443/srm/managerv2?SFN=/pnfs/desy.de/cms/tier2/store/user/jschulz/nTuples/WJets_V01/
# srm://dcache-se-cms.desy.de:8443/srm/managerv2?SFN=/pnfs/desy.de/cms/tier2/store/user/jschulz/nTuples/GVJets_V01/
 srm://dcache-se-cms.desy.de:8443/srm/managerv2?SFN=/pnfs/desy.de/cms/tier2/store/user/jschulz/nTuples/TTJets_V01/
#srm://dcache-se-cms.desy.de:8443/srm/managerv2?SFN=/pnfs/desy.de/cms/tier2/store/user/jschulz/nTuples/GJets_V01/
)
# settings
version="01"
files_per_job=20

for dataset in "${datasets[@]}"; do

    # get folder name as best description for job
    job_name=$(echo $dataset|rev|cut -d'/' -f2|rev)
    # Since root can't handle -, it will be substituted to _
    job_name=$(echo $job_name|sed 's/-/_/g')

    files=( $(srmls -offset 0 -count 999 $dataset|grep root|awk '{print $2 }') )
    # Ugly hack to get more than 1000 files (up to 2000).
    files+=( $(srmls -offset 1000 -count 1999 $dataset|grep root|awk '{print $2 }') )
    number_of_jobs=$(expr ${#files[@]} / $files_per_job + 1 )

    # just for testing purpurse
    #TMPDIR=/tmp


    for (( job=1; job<=$number_of_jobs; job++ )); do

        jobPrefix=${job_name}.${version}__${job}

        files_to_submit=""
        for (( i=$(expr $job \* $files_per_job - $files_per_job  ); i<$(expr $job \* $files_per_job ); i++ )); do
            if [[ "${files[$i]}" != "" ]]; then
                files_to_submit=$files_to_submit"dcap://dcache-cms-dcap.desy.de"${files[$i]}" "
            fi
        done # files for one job
        outputFileName=/scratch/hh/dust/naf/cms/user/kiesel/${jobPrefix}_tree.root

        # now that we have all information, get data
        script=$jobPrefix.sh

        echo export SCRAM_ARCH="slc5_amd64_gcc462" > $script
        echo export VO_CMS_SW_DIR=/cvmfs/cms.cern.ch >> $script
        echo source $VO_CMS_SW_DIR/cmsset_default.sh >> $script
        echo ini glite >> $script
        echo cd $HOME/CMSSW_5_3_8/src >> $script
        echo ini cmssw >> $script
        echo cmsenv >> $script
        echo cd $HOME/treeWriter >> $script

        echo ./executable $outputFileName $files_to_submit >> $script
        chmod +x $script
        qsub -b y -j y -l h_cpu=07:00:00 -l site=hh `pwd`/$jobPrefix.sh
        echo
    done # all jobs
done #dataset
